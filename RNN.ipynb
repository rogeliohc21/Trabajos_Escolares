{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Simple RNN\n",
        "Ejemplo canónico de una RNN para una tarea más básica, como la predicción de la próxima palabra en una secuencia de texto. Este tipo de tarea ilustra claramente cómo las RNN pueden manejar datos secuenciales.\n",
        "Importamos los módulos necesarios."
      ],
      "metadata": {
        "id": "fMuxVHj5k-VL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7nRvKpmkmlT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos de entrenamiento, es una cadena de texto."
      ],
      "metadata": {
        "id": "7PLsbhntlR0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fragmento del poema; Nocturno a Rosario\n",
        "# de Manuel Acuña\n",
        "\n",
        "text = '¡Pues bien! yo necesito, decirte que te adoro, decirte que te quiero con todo el corazón'"
      ],
      "metadata": {
        "id": "vPm3PoxKk4aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "se obtienen todas las palabras de nuestro texto"
      ],
      "metadata": {
        "id": "NbFMLP9bm9Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BehKQ5N3mL2I",
        "outputId": "cba25a38-ac76-4079-8bd3-d80075c4ae39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['¡Pues', 'bien!', 'yo', 'necesito,', 'decirte', 'que', 'te', 'adoro,', 'decirte', 'que', 'te', 'quiero', 'con', 'todo', 'el', 'corazón']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizacion\n",
        "word_to_idx = {word: idx for idx, word in enumerate(words)}\n",
        "idx_to_word = {idx: word for idx, word in enumerate(words)}\n",
        "print(word_to_idx)\n",
        "print(idx_to_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZLm3jEYmLzu",
        "outputId": "78c9ce8c-c400-4742-bafd-881baf9a2b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'¡Pues': 0, 'bien!': 1, 'yo': 2, 'necesito,': 3, 'decirte': 8, 'que': 9, 'te': 10, 'adoro,': 7, 'quiero': 11, 'con': 12, 'todo': 13, 'el': 14, 'corazón': 15}\n",
            "{0: '¡Pues', 1: 'bien!', 2: 'yo', 3: 'necesito,', 4: 'decirte', 5: 'que', 6: 'te', 7: 'adoro,', 8: 'decirte', 9: 'que', 10: 'te', 11: 'quiero', 12: 'con', 13: 'todo', 14: 'el', 15: 'corazón'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se preparan los datos, en el seq_length ocupamos cierto numero de palabras\n",
        "lo cual nos ayudara a predecir la siguiente palabra"
      ],
      "metadata": {
        "id": "SiXpfQf2nI3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 6\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(len(words) - seq_length):\n",
        "    seq_in = words[i:i + seq_length]\n",
        "    seq_out = words[i + seq_length]\n",
        "    X.append([word_to_idx[word] for word in seq_in])\n",
        "    y.append(word_to_idx[seq_out])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(X)\n",
        "print('*'*10)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYrGVbTXnL_7",
        "outputId": "0a7ae56d-4aa0-4814-e036-92af82a27c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  8  9]\n",
            " [ 1  2  3  8  9 10]\n",
            " [ 2  3  8  9 10  7]\n",
            " [ 3  8  9 10  7  8]\n",
            " [ 8  9 10  7  8  9]\n",
            " [ 9 10  7  8  9 10]\n",
            " [10  7  8  9 10 11]\n",
            " [ 7  8  9 10 11 12]\n",
            " [ 8  9 10 11 12 13]\n",
            " [ 9 10 11 12 13 14]]\n",
            "**********\n",
            "[10  7  8  9 10 11 12 13 14 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(words), 10, input_length=seq_length),\n",
        "    tf.keras.layers.SimpleRNN(32, activation='tanh', input_shape=(seq_length, 10)),\n",
        "    tf.keras.layers.Dense(len(words), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "kec4GcgooymQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "rkv-XkNepQz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io65jS9YpX-V",
        "outputId": "6f5c2adc-596a-45de-d23b-9f968b31482c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.7364\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7225\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7084\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6941\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6795\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6645\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6490\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6329\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6163\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5989\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5807\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5617\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5418\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5210\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4992\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4763\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.4524\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.4275\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4015\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3745\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3466\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3177\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2880\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2576\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2265\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1948\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1626\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.1299\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0968\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0632\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0291\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9943\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.9589\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.9226\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8853\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8470\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8077\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.7673\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.7259\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6836\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6406\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5971\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5533\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5095\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4660\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4230\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.3807\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3392\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.2987\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.2592\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e8fb3092320>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generación de secuencia de palabras\n",
        "seed_text = '¡Pues bien! yo necesito, decirte que'\n",
        "seed_words = seed_text.split()\n",
        "generated_words = list(seed_words)\n",
        "\n",
        "for _ in range(2):\n",
        "    x = np.array([[word_to_idx[word] for word in seed_words]])\n",
        "    y_pred = model.predict(x)\n",
        "    next_word_idx = np.argmax(y_pred)\n",
        "    next_word = idx_to_word[next_word_idx]\n",
        "    generated_words.append(next_word)\n",
        "    seed_words = seed_words[1:] + [next_word]\n",
        "\n",
        "generated_text = ' '.join(generated_words)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu5kZlIMpgFQ",
        "outputId": "90393ab1-6ece-4682-aae2-941e2b75f7a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 295ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "¡Pues bien! yo necesito, decirte que te adoro,\n"
          ]
        }
      ]
    }
  ]
}